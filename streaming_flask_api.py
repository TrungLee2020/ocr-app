import asyncio
import logging
from logging.handlers import RotatingFileHandler
import mimetypes
from flask import Flask, request, jsonify, Response
from flask_cors import CORS
import fitz  # PyMuPDF
import io
import base64
import requests
from PIL import Image
from concurrent.futures import ThreadPoolExecutor
import redis
import hashlib
import json
import functools
import time
import threading
from queue import Queue


# Thi·∫øt l·∫≠p logging
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
file_handler = RotatingFileHandler('smartocr.log', maxBytes=10*1024*1024, backupCount=5, encoding='utf-8')
file_handler.setFormatter(formatter)
stream_handler = logging.StreamHandler()
stream_handler.setFormatter(formatter)
logger.addHandler(file_handler)
logger.addHandler(stream_handler)

# Kh·ªüi t·∫°o Flask app
app = Flask(__name__)
CORS(app)

# C·∫•u h√¨nh
OCR_API_URL = 'https://c4f6-1-54-8-15.ngrok-free.app/ocr'  # Thay b·∫±ng URL API OCR
OCR_API_KEY = 'YOUR_OCR_API_KEY'  # Thay b·∫±ng API key OCR
API_KEY = 'YOUR_FLASK_API_KEY_HERE'  # Thay b·∫±ng key cho x√°c th·ª±c
app.config['MAX_CONTENT_LENGTH'] = 10 * 1024 * 1024  # 10MB/file

# K·∫øt n·ªëi Redis
try:
    redis_client = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)
    # Test connection
    redis_client.ping()
    logger.info('K·∫øt n·ªëi Redis th√†nh c√¥ng')
except:
    redis_client = None
    logger.warning('Kh√¥ng th·ªÉ k·∫øt n·ªëi Redis, cache s·∫Ω b·ªã v√¥ hi·ªáu h√≥a')

# Thread pool v·ªõi s·ªë l∆∞·ª£ng t·ªëi ∆∞u
executor = ThreadPoolExecutor(max_workers=4)

# Middleware x√°c th·ª±c
def require_api_key(f):
    @functools.wraps(f)
    def decorated(*args, **kwargs):
        api_key = request.headers.get('X-API-Key')
        if not api_key or api_key != API_KEY:
            logger.warning('Y√™u c·∫ßu kh√¥ng ƒë∆∞·ª£c x√°c th·ª±c')
            return jsonify({'error': 'API key kh√¥ng h·ª£p l·ªá'}), 401
        return f(*args, **kwargs)
    return decorated

# T·∫°o key cache v·ªõi th√™m th√¥ng tin file
def get_cache_key(file_data, params):
    hash_obj = hashlib.sha256()
    hash_obj.update(file_data)
    hash_obj.update(json.dumps(params, sort_keys=True).encode())
    return hash_obj.hexdigest()

# Chuy·ªÉn PDF th√†nh danh s√°ch h√¨nh ·∫£nh v·ªõi t·ªëi ∆∞u h√≥a
def pdf_to_images(pdf_data):
    logger.info('B·∫Øt ƒë·∫ßu t√°ch c√°c trang t·ª´ PDF')
    try:
        # pdf_data ƒë√£ l√† bytes, kh√¥ng c·∫ßn seek/read
        pdf_document = fitz.open(stream=pdf_data, filetype="pdf")
        images = []

        # T·ªëi ∆∞u h√≥a: X·ª≠ l√Ω t·ª´ng trang ƒë·ªôc l·∫≠p, gi·∫£m b·ªô nh·ªõ
        for page_number in range(len(pdf_document)):
            page = pdf_document.load_page(page_number)
            # S·ª≠ d·ª•ng DPI 150 ƒë·ªÉ ƒë·∫£m b·∫£o ch·∫•t l∆∞·ª£ng OCR t·ªët
            pix = page.get_pixmap(matrix=fitz.Matrix(150/72, 150/72), colorspace="rgb")
            img_data = pix.tobytes("png")
            img = Image.open(io.BytesIO(img_data))
            images.append(img)
            pix = None  # Gi·∫£i ph√≥ng b·ªô nh·ªõ

        pdf_document.close()
        logger.info(f'T√°ch th√†nh c√¥ng {len(images)} trang')
        return images
    except Exception as e:
        logger.error(f'L·ªói khi t√°ch PDF: {str(e)}')
        raise

# G·ªçi API OCR - SYNC VERSION
def process_page_with_custom_ocr(image, language, prompt=None):
    logger.info('=== G·ªçi Custom OCR API ===')
    try:
        # Chuy·ªÉn ƒë·ªïi h√¨nh ·∫£nh th√†nh bytes ƒë·ªÉ g·ª≠i
        buffered = io.BytesIO()
        if image.mode != 'RGB':
            image = image.convert('RGB')
        image.save(buffered, format="JPEG", optimize=True, quality=85)
        img_bytes = buffered.getvalue()
        buffered.close()

        # T·∫°o cache key v√† log ƒë·ªÉ debug
        cache_key = get_cache_key(img_bytes, {'language': language, 'prompt': prompt})
        logger.info(f"=== Cache key: {cache_key[:16]}... ===")
        
        # Ki·ªÉm tra cache tr∆∞·ªõc
        if redis_client:
            try:
                cached_result = redis_client.get(cache_key)
                if cached_result:
                    logger.info('=== L·∫•y t·ª´ cache ===')
                    return json.loads(cached_result)
                else:
                    logger.info('=== Kh√¥ng c√≥ cache, g·ªçi API ===')
            except Exception as e:
                logger.warning(f'=== L·ªói cache: {e}')

        # G·ªçi API
        logger.info('=== G·ªçi API OCR... ===')
        
        # Chu·∫©n b·ªã request
        img_name = f"page_{int(time.time())}.jpg"
        files = {"origin_file": (img_name, img_bytes, "image/jpeg")}
        data = {"prompt": prompt or "OCR toaÃÄn b√¥Ã£ th√¥ng tin trong ·∫£nh"}
        
        logger.info(f"=== URL: {OCR_API_URL} ===")
        logger.info(f"=== File: {img_name} ===")
        logger.info(f"Prompt: {data['prompt']}")

        # G·ªçi API ƒë·ªìng b·ªô
        start_time = time.time()
        response = requests.post(
            OCR_API_URL, 
            files=files, 
            data=data,
            timeout=120
        )
        end_time = time.time()
        
        logger.info(f"=== Request time: {end_time - start_time:.2f}s ===")
        logger.info(f"=== Status: {response.status_code} ===")
        
        if response.status_code == 200:
            logger.info("=== API SUCCESS! ===")
            api_response = response.json()
        else:
            logger.error(f"=== API FAILED! Status: {response.status_code} ===")
            logger.error(f"Response: {response.text}")
            response.raise_for_status()
        
        # X·ª≠ l√Ω response
        text = api_response.get('data', '')
        task_id = api_response.get('task_id', '')
        processing_time = api_response.get('Time process', 0)

        logger.info(f"=== Text: {text[:100]}{'...' if len(text) > 100 else ''} ===")
        logger.info(f"=== Task ID: {task_id} ===")
        logger.info(f"=== Process time: {processing_time}s ===")

        # T·∫°o result
        result = {
            'text': text,
            'task_id': task_id,
            'processing_time': processing_time,
            'confidence': None,
            'structuredData': None
        }
        
        # L∆∞u v√†o cache
        if redis_client:
            try:
                redis_client.setex(cache_key, 86400, json.dumps(result))
                logger.info("üíæ Saved to cache")
            except Exception as e:
                logger.warning(f'‚ö†Ô∏è Cache save error: {e}')
                
        return result
        
    except Exception as e:
        logger.error(f'=== OCR Error: {str(e)} ')
        raise

# Worker function cho threading
def ocr_worker(task_queue, result_queue):
    """Worker thread ƒë·ªÉ x·ª≠ l√Ω OCR tasks"""
    while True:
        task = task_queue.get()
        if task is None:
            break
        
        try:
            filename, page_num, image, language, prompt, endpoint_type, document_type, options = task
            
            # X·ª≠ l√Ω OCR
            result = process_page_with_custom_ocr(image, language, prompt)
            
            # T·∫°o page data
            page_data = {
                'pageNumber': page_num,
                'text': result['text'],
                'task_id': result.get('task_id'),
                'processing_time': result.get('processing_time', 0)
            }
            
            # Th√™m metadata cho advanced
            if endpoint_type == 'advanced':
                page_data.update({
                    'confidence': result.get('confidence'),
                    'structuredData': result.get('structuredData'),
                    'metadata': {
                        'document_type': document_type,
                        'prompt_used': prompt,
                        'options': options
                    }
                })
            
            # G·ª≠i k·∫øt qu·∫£
            result_queue.put({
                'filename': filename,
                'page': page_data,
                'success': True
            })
            
        except Exception as e:
            logger.error(f'Worker error: {e}')
            result_queue.put({
                'filename': filename,
                'page': {
                    'pageNumber': page_num,
                    'text': '',
                    'error': str(e),
                    'task_id': None,
                    'processing_time': 0
                },
                'success': False
            })
        finally:
            task_queue.task_done()

# Generator function for streaming OCR results - SYNC VERSION
def stream_ocr_results(files_data, endpoint_type, language=None, document_type=None, options=None, prompt=None):
    """Generator ƒë·ªÉ stream k·∫øt qu·∫£ OCR - s·ª≠ d·ª•ng threading thay v√¨ async"""
    
    # T·∫°o queue cho tasks v√† results
    task_queue = Queue()
    result_queue = Queue()
    
    # ƒê·∫øm t·ªïng s·ªë tasks
    total_tasks = 0
    
    # Th√™m t·∫•t c·∫£ tasks v√†o queue
    for file_info in files_data:
        filename, file_data, mime_type = file_info
        
        logger.info(f"=== Preparing file: {filename} ===")
        
        try:
            if mime_type not in ['application/pdf', 'image/jpeg', 'image/png']:
                yield f"data: {json.dumps({'filename': filename, 'error': 'ƒê·ªãnh d·∫°ng file kh√¥ng ƒë∆∞·ª£c h·ªó tr·ª£'})}\n\n"
                continue

            # X·ª≠ l√Ω file
            if mime_type == 'application/pdf':
                images = pdf_to_images(file_data)
                for i, img in enumerate(images, 1):
                    task_queue.put((filename, i, img, language or 'Ti·∫øng Vi·ªát', prompt, endpoint_type, document_type, options))
                    total_tasks += 1
            else:
                # X·ª≠ l√Ω h√¨nh ·∫£nh ƒë∆°n
                image = Image.open(io.BytesIO(file_data))
                task_queue.put((filename, 1, image, language or 'Ti·∫øng Vi·ªát', prompt, endpoint_type, document_type, options))
                total_tasks += 1
                
        except Exception as e:
            logger.error(f'L·ªói chu·∫©n b·ªã file {filename}: {e}')
            yield f"data: {json.dumps({'filename': filename, 'error': str(e)})}\n\n"
    
    # Kh·ªüi t·∫°o worker threads
    worker_count = min(4, total_tasks)  # T·ªëi ƒëa 4 workers
    workers = []
    
    for _ in range(worker_count):
        worker = threading.Thread(target=ocr_worker, args=(task_queue, result_queue))
        worker.daemon = True
        worker.start()
        workers.append(worker)
    
    # Thu th·∫≠p k·∫øt qu·∫£
    completed_tasks = 0
    while completed_tasks < total_tasks:
        try:
            # Ch·ªù k·∫øt qu·∫£ v·ªõi timeout
            result = result_queue.get(timeout=60)  # 60s timeout
            yield f"data: {json.dumps(result)}\n\n"
            completed_tasks += 1
            result_queue.task_done()
        except:
            # Timeout ho·∫∑c l·ªói kh√°c
            break
    
    # D·ª´ng workers
    for _ in workers:
        task_queue.put(None)
    
    # Ch·ªù workers ho√†n th√†nh
    for worker in workers:
        worker.join(timeout=5)

# Endpoint Nh·∫≠n d·∫°ng c∆° b·∫£n v·ªõi streaming - FIXED
@app.route('/ocr/basic', methods=['POST'])
@require_api_key
def basic_ocr():
    logger.info('=== Nh·∫≠n y√™u c·∫ßu Basic OCR ===')
    
    try:
        # L·∫•y parameters
        files = request.files.getlist('file')
        if not files or all(f.filename == '' for f in files):
            return jsonify({'error': 'Vui l√≤ng t·∫£i l√™n √≠t nh·∫•t m·ªôt file'}), 400
            
        language = request.form.get('language', 'Ti·∫øng Vi·ªát')
        
        # ƒê·ªçc file data TR∆Ø·ªöC KHI pass v√†o generator
        files_data = []
        for file in files:
            if file.filename == '':
                continue
                
            # ƒê·ªçc file data
            file.seek(0)
            file_data = file.read()
            
            # X√°c ƒë·ªãnh mime type
            mime_type, _ = mimetypes.guess_type(file.filename)
            if not mime_type:
                if file.filename.lower().endswith('.pdf'):
                    mime_type = 'application/pdf'
                elif file.filename.lower().endswith(('.jpg', '.jpeg')):
                    mime_type = 'image/jpeg'
                elif file.filename.lower().endswith('.png'):
                    mime_type = 'image/png'
                else:
                    continue
                    
            files_data.append((file.filename, file_data, mime_type))
        
        if not files_data:
            return jsonify({'error': 'Kh√¥ng c√≥ file h·ª£p l·ªá ƒë·ªÉ x·ª≠ l√Ω'}), 400
        
        # T·∫°o generator v√† wrap trong Response
        def generate():
            try:
                for item in stream_ocr_results(files_data, 'basic', language=language):
                    yield item
            except Exception as e:
                logger.error(f'Basic OCR stream error: {e}')
                yield f"data: {json.dumps({'error': str(e)})}\n\n"
        
        return Response(
            generate(),
            mimetype='text/event-stream',
            headers={
                'Cache-Control': 'no-cache',
                'Connection': 'keep-alive',
                'Access-Control-Allow-Origin': '*',
                'Access-Control-Allow-Headers': 'X-API-Key, Content-Type',
            }
        )
        
    except Exception as e:
        logger.error(f'Basic OCR error: {str(e)}')
        return jsonify({'error': str(e)}), 500

# Endpoint Nh·∫≠n d·∫°ng n√¢ng cao v·ªõi streaming - FIXED
@app.route('/ocr/advanced', methods=['POST'])
@require_api_key  
def advanced_ocr():
    logger.info('üì• Nh·∫≠n y√™u c·∫ßu Advanced OCR')
    
    try:
        # L·∫•y parameters
        files = request.files.getlist('file')
        if not files or all(f.filename == '' for f in files):
            return jsonify({'error': 'Vui l√≤ng t·∫£i l√™n √≠t nh·∫•t m·ªôt file'}), 400
            
        document_type = request.form.get('documentType', 'Kh√°c')
        prompt = request.form.get('prompt', '')
        options_str = request.form.get('options', '{}')
        
        # Parse options safely
        try:
            options = json.loads(options_str)
        except:
            options = {}
        
        # ƒê·ªçc file data TR∆Ø·ªöC KHI pass v√†o generator
        files_data = []
        for file in files:
            if file.filename == '':
                continue
                
            # ƒê·ªçc file data
            file.seek(0)
            file_data = file.read()
            
            # X√°c ƒë·ªãnh mime type
            mime_type, _ = mimetypes.guess_type(file.filename)
            if not mime_type:
                if file.filename.lower().endswith('.pdf'):
                    mime_type = 'application/pdf'
                elif file.filename.lower().endswith(('.jpg', '.jpeg')):
                    mime_type = 'image/jpeg'
                elif file.filename.lower().endswith('.png'):
                    mime_type = 'image/png'
                else:
                    continue
                    
            files_data.append((file.filename, file_data, mime_type))
        
        if not files_data:
            return jsonify({'error': 'Kh√¥ng c√≥ file h·ª£p l·ªá ƒë·ªÉ x·ª≠ l√Ω'}), 400
        
        # T·∫°o generator v√† wrap trong Response
        def generate():
            try:
                for item in stream_ocr_results(
                    files_data, 'advanced', 
                    language='Ti·∫øng Vi·ªát',
                    document_type=document_type,
                    options=options,
                    prompt=prompt
                ):
                    yield item
            except Exception as e:
                logger.error(f'Advanced OCR stream error: {e}')
                yield f"data: {json.dumps({'error': str(e)})}\n\n"
        
        return Response(
            generate(),
            mimetype='text/event-stream',
            headers={
                'Cache-Control': 'no-cache',
                'Connection': 'keep-alive',
                'Access-Control-Allow-Origin': '*',
                'Access-Control-Allow-Headers': 'X-API-Key, Content-Type',
            }
        )
        
    except Exception as e:
        logger.error(f'Advanced OCR error: {str(e)}')
        return jsonify({'error': str(e)}), 500

# Function ki·ªÉm tra API OCR
# def check_ocr_api_health():
#     """Ki·ªÉm tra k·∫øt n·ªëi ƒë·∫øn API OCR"""
#     try:
#         # Th·ª≠ g·ªçi API OCR v·ªõi timeout ng·∫Øn
#         response = requests.get(
#             f"{OCR_API_URL.rstrip('/ocr')}/health",
#             timeout=5
#         )
#         if response.status_code == 200:
#             return 'healthy'
#         else:
#             return f'unhealthy (status: {response.status_code})'
#     except requests.exceptions.Timeout:
#         return 'unhealthy (timeout)'
#     except requests.exceptions.ConnectionError:
#         return 'unhealthy (connection failed)'
#     except Exception as e:
#         return f'unhealthy (error: {str(e)})'
    
# Endpoint ki·ªÉm tra tr·∫°ng th√°i
@app.route('/health', methods=['GET'])
def health_check():
    status = {
        'status': 'healthy',
        'redis': 'connected' if redis_client else 'disconnected',
        'ocr_api': 'configured',
        'streaming': 'enabled (threading-based)'
    }
    return jsonify(status)

# Error handlers
@app.errorhandler(413)
def too_large(e):
    return jsonify({'error': 'File qu√° l·ªõn. K√≠ch th∆∞·ªõc t·ªëi ƒëa l√† 10MB'}), 413

@app.errorhandler(500)
def internal_error(e):
    logger.error(f'Internal server error: {str(e)}')
    return jsonify({'error': 'L·ªói m√°y ch·ªß n·ªôi b·ªô'}), 500

if __name__ == '__main__':
    logger.info('=============Kh·ªüi ƒë·ªông Flask server v·ªõi threading-based streaming=============')
    app.run(debug=False, host='0.0.0.0', port=5000)